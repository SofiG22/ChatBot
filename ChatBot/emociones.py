from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
from flask import Flask, request, jsonify
from flask_cors import CORS

# Initialize Flask app
app = Flask(__name__)
CORS(app)

print("‚è≥ Cargando modelo de an√°lisis de sentimientos...")

# Cargar el modelo y el tokenizador de Hugging Face
modelo = "nlptown/bert-base-multilingual-uncased-sentiment"
try:
    tokenizer = AutoTokenizer.from_pretrained(modelo)
    model = AutoModelForSequenceClassification.from_pretrained(modelo)
    print(f"‚úÖ Modelo {modelo} cargado correctamente")
except Exception as e:
    print(f"‚ùå Error al cargar el modelo: {e}")
    print("‚ö†Ô∏è Intentando con un modelo alternativo...")
    # Intentar con un modelo alternativo como fallback
    modelo = "cardiffnlp/twitter-xlm-roberta-base-sentiment"
    tokenizer = AutoTokenizer.from_pretrained(modelo)
    model = AutoModelForSequenceClassification.from_pretrained(modelo)
    print(f"‚úÖ Modelo alternativo {modelo} cargado correctamente")

# Mapeo personalizado de emociones seg√∫n el frontend
# El modelo BERT de sentimientos tiene 5 clases (0-4), las mapeamos a las emociones del frontend
emotion_mapping = {
    0: "Triste/a",        # Muy negativo -> Triste
    1: "Frustrado/a",     # Negativo -> Frustrado
    2: "Neutral/a",       # Neutral -> Neutral
    3: "Feliz/a",         # Positivo -> Feliz
    4: "Orgulloso/a"      # Muy positivo -> Orgulloso
}

# Mapeo secundario para emociones adicionales basadas en an√°lisis de texto
secondary_emotions = {
    "error": "Confundido/a",
    "problema": "Frustrado/a", 
    "molest": "Enojado/a",
    "incre√≠ble": "Sorpresa/a",
    "amo": "Amor/a",
    "miedo": "Miedo/a",
    "confus": "Confundido/a",
    "verguenz": "Avergonzado/a",
    "orgull": "Orgulloso/a",
    "cansan": "Cansado/a",
    "nervios": "Nervioso/a",
    "frustra": "Frustrado/a",
    "aburr": "Aburrido/a",
    "relaja": "Relajado/a",
    "ansio": "Ansioso/a",
    "inspira": "Inspirado/a",
    "desinter√©s": "Desinteresado/a"
}

def get_secondary_emotion(texto, primary_emotion):
    """
    Analiza palabras clave en el texto para detectar emociones secundarias
    """
    texto_lower = texto.lower()
    
    # Si detectamos palabras clave espec√≠ficas, asignamos emociones secundarias
    for keyword, emotion in secondary_emotions.items():
        if keyword in texto_lower:
            return emotion
    
    # Si no encontramos palabras clave, mantenemos la emoci√≥n primaria
    return primary_emotion

def detectar_emocion(texto):
    """
    Analiza el sentimiento de un texto usando el modelo preentrenado
    Retorna la emoci√≥n detectada y el nivel de confianza
    """
    try:
        # Preprocesar el texto
        inputs = tokenizer(texto, return_tensors="pt", truncation=True, padding=True)
        
        # Realizar la predicci√≥n
        with torch.no_grad():
            outputs = model(**inputs)
            logits = outputs.logits
        
        # Obtener la predicci√≥n principal
        predicted_class = torch.argmax(logits).item()
        probabilities = torch.softmax(logits, dim=1)[0]
        
        # Obtener la emoci√≥n primaria seg√∫n el modelo de sentimientos
        primary_emotion = emotion_mapping[predicted_class]
        
        # Buscar posibles emociones secundarias basadas en palabras clave
        detected_emotion = get_secondary_emotion(texto, primary_emotion)
        
        # Calcular confianza
        confidence = float(probabilities[predicted_class].item() * 100)
        
        # Obtener emoji correspondiente
        emoji = get_emoji_for_status(detected_emotion)
        
        return {
            "success": True, 
            "texto": texto,
            "emocion": detected_emotion,
            "emoji": emoji,
            "confianza": confidence,
            "emocion_base": primary_emotion
        }
    except Exception as e:
        return {"success": False, "error": str(e)}

def get_emoji_for_status(status):
    """Devuelve el emoji correspondiente a cada estado emocional"""
    emoji_map = {
        'Feliz/a': 'üòä', 
        'Triste/a': 'üòû',
        'Enojado/a': 'üò°', 
        'Neutral/a': 'üòê',
        'Sorpresa/a': 'üò≤',
        'Amor/a': '‚ù§Ô∏è',
        'Miedo/a': 'üò®',
        'Confundido/a': 'ü§î',
        'Avergonzado/a': 'üò≥',
        'Orgulloso/a': 'üòé',
        'Cansado/a': 'üò¥',
        'Nervioso/a': 'üò¨',
        'Frustrado/a': 'üò§',
        'Desinteresado/a': 'üòí',
        'Relajado/a': 'üòå',
        'Ansioso/a': 'üòü',
        'Aburrido/a': 'üòë',
        'Inspirado/a': '‚ú®'
    }
    return emoji_map.get(status, '')

@app.route('/detectar-emocion', methods=['POST'])
def detectar_emocion_endpoint():
    """Endpoint para detectar la emoci√≥n en un texto."""
    
    # Verificar si se recibi√≥ JSON
    if not request.is_json:
        return jsonify({
            "success": False, 
            "error": "La solicitud debe ser en formato JSON."
        }), 400
    
    # Obtener el texto del JSON
    data = request.get_json()
    if not data or "texto" not in data:
        return jsonify({
            "success": False,
            "error": "Formato incorrecto. Se requiere el campo 'texto'."
        }), 400
    
    texto = data["texto"]
    
    # Analizar la emoci√≥n
    resultado = detectar_emocion(texto)
    return jsonify(resultado)

@app.route('/batch', methods=['POST'])
def batch_analysis():
    """Endpoint para analizar m√∫ltiples textos en una sola solicitud"""
    
    # Verificar si se recibi√≥ JSON
    if not request.is_json:
        return jsonify({
            "success": False, 
            "error": "La solicitud debe ser en formato JSON."
        }), 400
    
    # Obtener la lista de textos
    data = request.get_json()
    if not data or "textos" not in data or not isinstance(data["textos"], list):
        return jsonify({
            "success": False,
            "error": "Formato incorrecto. Se requiere el campo 'textos' como lista."
        }), 400
    
    textos = data["textos"]
    
    # Analizar cada texto
    resultados = []
    for texto in textos:
        resultado = detectar_emocion(texto)
        resultados.append(resultado)
    
    return jsonify({
        "success": True,
        "resultados": resultados
    })

@app.route('/estado', methods=['GET'])
def health_check():
    """Endpoint para verificar el estado del servicio"""
    return jsonify({
        "status": "online",
        "model": modelo,
        "version": "1.0.0",
        "emociones_soportadas": list(set(emotion_mapping.values()))
    })

if __name__ == '__main__':
    print("üöÄ Servicio de an√°lisis de sentimientos iniciado en http://localhost:5003")
    print("üìå Endpoints disponibles:")
    print("   - /detectar-emocion: Detecta la emoci√≥n en un texto proporcionado")
    print("   - /batch: Analiza m√∫ltiples textos en una sola solicitud")
    print("   - /estado: Verifica el estado del servicio")
    app.run(host='0.0.0.0', port=5003, debug=True)